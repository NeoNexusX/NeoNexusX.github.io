<!DOCTYPE html><html class="appearance-auto" lang="chinese"><head><meta charset="UTF-8"><title>Spark快速大数据分析——Spark的Hadoop配置（叁）</title><meta name="description" content="YOU CAN REDO"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q || []).push(arguments)},i[r].l=1 * new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'G-E0GBC11CTD', 'neonexusx.github.io');
ga('send', 'pageview');</script><!-- End Google Analytics -->
<!-- Baidu Analytics --><script>var _hmt = _hmt || [];
(function() {
var hm = document.createElement("script");
hm.src = "//hm.baidu.com/hm.js?" + '1c102c8d6549c8317b34036a36f85904';
var s = document.getElementsByTagName("script")[0];
s.parentNode.insertBefore(hm, s);
})();</script><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="Spark快速大数据分析——Spark的Hadoop配置（叁）


软件环境：

Hadoop-3.2
Spark-3.1.3
JDK 8
WSL2 Ubuntu20.04
Windos10 20H2



Hadoop单机配置(非分布式)

注意！


Hadoop伪分布式配置

Hadoop配置文件说明
注意！
注意！
Hadoop无法正常启动的解决方法


运行Hadoop伪分布式实例

注意！




[TOC]
Hadoop单机配置(非分布式)
Hadoop 默认模式为非分布式模式（本地模式），无需进行其他配置即可运行。非分布式即单 Java 进程，方便进行 调试。
现在我们可以执行例子来测试一下Hadoop 的运行是否正常。
Hadoop 附带了丰富的例子（运行 ./bin/hadoop jar.."><script src="//unpkg.com/valine/dist/Valine.min.js"></script><meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">NeoNexus's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Spark快速大数据分析——Spark的Hadoop配置（叁）</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">点击返回顶部</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">Spark快速大数据分析——Spark的Hadoop配置（叁）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-text">软件环境：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-text">Hadoop单机配置(非分布式)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-text">注意！</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-text">Hadoop伪分布式配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-text">Hadoop配置文件说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-text">注意！</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-text">注意！</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-text">Hadoop无法正常启动的解决方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-text">运行Hadoop伪分布式实例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-text">注意！</span></a></li></ol></li></ol></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/Spark"><i class="tag post-item-tag">Spark</i></a><a href="/tags/Hadoop"><i class="tag post-item-tag">Hadoop</i></a><a href="/tags/Scala"><i class="tag post-item-tag">Scala</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">Spark快速大数据分析——Spark的Hadoop配置（叁）</h1><time class="has-text-grey" datetime="2024-10-21T16:00:00.000Z">2024-10-22</time><article class="mt-2 post-content"><h1><span id="spark快速大数据分析spark的hadoop配置叁">Spark快速大数据分析——Spark的Hadoop配置（叁）</span></h1>
<img src="https://s2.loli.net/2024/09/29/JGuU5PY7BSrQzAX.jpg" alt="[lab.magiconch.com][福音戰士標題生成器]-1727612092601" style="zoom:50%;">
<img src="https://s2.loli.net/2023/09/18/zXu5EpoCmKH8FiJ.jpg" alt="标准监督" style="zoom: 50%;">
<h2><span id="软件环境">软件环境：</span></h2>
<ul>
<li><strong>Hadoop-3.2</strong></li>
<li><strong>Spark-3.1.3</strong></li>
<li><strong>JDK 8</strong></li>
<li><strong>WSL2</strong> <strong>Ubuntu20.04</strong></li>
<li><strong>Windos10 20H2</strong></li>
</ul>
<!-- toc -->
<ul>
<li><a href="#hadoop%E5%8D%95%E6%9C%BA%E9%85%8D%E7%BD%AE%E9%9D%9E%E5%88%86%E5%B8%83%E5%BC%8F">Hadoop单机配置(非分布式)</a>
<ul>
<li><a href="#%E6%B3%A8%E6%84%8F">注意！</a></li>
</ul>
</li>
<li><a href="#hadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE">Hadoop伪分布式配置</a>
<ul>
<li><a href="#hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E">Hadoop配置文件说明</a></li>
<li><a href="#%E6%B3%A8%E6%84%8F-1">注意！</a></li>
<li><a href="#%E6%B3%A8%E6%84%8F-2">注意！</a></li>
<li><a href="#hadoop%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95">Hadoop无法正常启动的解决方法</a></li>
</ul>
</li>
<li><a href="#%E8%BF%90%E8%A1%8Chadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E4%BE%8B">运行Hadoop伪分布式实例</a>
<ul>
<li><a href="#%E6%B3%A8%E6%84%8F-3">注意！</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<p>[TOC]</p>
<h2><span id="hadoop单机配置非分布式">Hadoop单机配置(非分布式)</span></h2>
<p>Hadoop 默认模式为非分布式模式（本地模式），无需进行其他配置即可运行。非分布式即单 Java 进程，方便进行 调试。</p>
<p>现在我们可以执行例子来测试一下Hadoop 的运行是否正常。</p>
<p>Hadoop 附带了丰富的例子（运行 ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar 可以看到所有例子），包括 wordcount、 terasort、join、grep 等。</p>
<p>在此我们选择运行grep例子，我们将input文件夹的所有文件作为输入，筛选当中符合正则表达式 dfs[a-z.]+ 的单 词并统计出现的次数，最后输出结果到 output 文件夹中。</p>
<p>首先切换到hadoop用户下：</p>
<pre><code class="language-ssh">jszszzy@LAPTOP-74GAR8S9:~$ su hadoop
</code></pre>
<p>切换对应文件夹下：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/home/jszszzy$ cd /usr/local/hadoop
</code></pre>
<p>创建一个input文件夹，把配置文件拷贝过来，将配置文件作为输入文件：</p>
<pre><code>hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ mkdir ./input
hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ cp ./etc/hadoop/*.xml ./input
</code></pre>
<p>最后调用运行，注意不要换行！（显示的可能有换行），注意版本和你本机安装的版本相对应：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hadoop jar./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
</code></pre>
<p>如果在这个地方产生报错：</p>
<pre><code class="language-shell">Error: Could not find or load main class jar..share.hadoop.mapreduce.hadoop
</code></pre>
<p>请删除hadoop重新解压一下，删除命令如下，解压命令参考第三篇：</p>
<pre><code class="language-shell">cd /usr/local
</code></pre>
<pre><code class="language-shell">sudo rm -r hadoop
</code></pre>
<p>等待运行完成后查看结果：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ cat ./output/*
1       dfsadmin
</code></pre>
<p>完成后结果如下：</p>
<p><img src="https://s2.loli.net/2024/09/29/xeak7WG54hVpm2o.png" alt="1"></p>
<p>显示符合正则的单词 dfsadmin 出现了1次。</p>
<h3><span id="注意">注意！</span></h3>
<p>注意，Hadoop 默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将 ./output 删除。</p>
<p>删除命令：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ rm -r ./output
</code></pre>
<h2><span id="hadoop伪分布式配置">Hadoop伪分布式配置</span></h2>
<p>Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。</p>
<p>Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/ 中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfssite.xml 。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。</p>
<p>修改配置文件 core-site.xml： vim ./etc/hadoop/core-site.xml ，将当中的</p>
<pre><code class="language-ssh">&lt;configuration&gt;
&lt;/configuration&gt;
</code></pre>
<p>修改为下面配置：</p>
<pre><code class="language-ssh">&lt;configuration&gt;
 	&lt;property&gt;
 		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
 		&lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;
		 &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;
 	&lt;/property&gt;
 	&lt;property&gt;
 		&lt;name&gt;fs.defaultFS&lt;/name&gt;
		 &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
	 &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre>
<p>同样的，修改配置文件 hdfs-site.xml：</p>
<pre><code class="language-ssh">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;1&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
		&lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
		&lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<h3><span id="hadoop配置文件说明">Hadoop配置文件说明</span></h3>
<p>Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模 式切换回非分布式模式，需要删除 core-site.xml 中的配置项。</p>
<p>此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有 配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系 统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。</p>
<p>我们继续回到配置：</p>
<p>配置完成后，执行 NameNode 的格式化，注意这里路径是什么:</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hdfs namenode -format
</code></pre>
<p>成功的话，会看到 “successfully formatted” 的提示，具体返回信息类似如下：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hdfs namenode -format
WARNING: /usr/local/hadoop/logs does not exist. Creating.
2022-04-14 13:20:01,596 INFO namenode.NameNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = LAPTOP-74GAR8S9.localdomain/127.0.1.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.
</code></pre>
<p><img src="https://s2.loli.net/2024/09/29/y4HaB7jmtohMGkJ.png" alt="2"></p>
<h3><span id="注意">注意！</span></h3>
<p>如果在这一步报错：</p>
<p><strong>Error: JAVA_HOME is not set and could not be found.</strong></p>
<p>则说明之前设置 JAVA_HOME 环境变量那边就没设置好，请按教程先设置好 JAVA_HOME 变量，否则后面的过程都是进行不下去 。</p>
<p>如果已经按照前面教程在.bashrc文件中设置了JAVA_HOME。还是出现 Error: JAVA_HOME is not set and could not be found. 的错误。</p>
<p>那么，请到hadoop的安装目录修改配置文件/usr/local/hadoop/etc/hadoop/hadoop-env.sh”，在里面找到“export JAVA_HOME=${JAVA_HOME}”这行，然后，把它修改成JAVA安装路径的具体地址，比 如，“export JAVA_HOME=/usr/lib/jvm/default-java”，然后，再次启动Hadoop。</p>
<p>设置后仍报错：</p>
<p><img src="https://s2.loli.net/2024/09/29/7lAQHfOWvVSZ28b.png" alt="3"></p>
<p>打开环境配置文件：</p>
<p>添加：<code>export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64</code></p>
<p><img src="https://s2.loli.net/2024/09/29/cnD3CpoeQkMh8NT.png" alt="4"></p>
<p>接着开启NameNode和DataNode守护进程:</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ cd /usr/local/hadoop
hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./sbin/start-dfs.sh
</code></pre>
<p>输入命令以后开始运行：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ cd /usr/local/hadoop
hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./sbin/start-dfs.sh
</code></pre>
<p>如果有报错如下：</p>
<pre><code class="language-shell">hadoop@LAPTOP-HO0AHQKI:/usr/local/hadoop$ sudo ./sbin/start-dfs.sh
WARNING: HADOOP_SECURE_DN_USER has been replaced by HDFS_DATANODE_SECURE_USER. Using value of HADOOP_SECURE_DN_USER.
Starting namenodes on [localhost]
localhost: root@localhost: Permission denied (publickey).
Starting datanodes
localhost: root@localhost: Permission denied (publickey).
Starting secondary namenodes [LAPTOP-HO0AHQKI]
LAPTOP-HO0AHQKI: root@laptop-ho0ahqki: Permission denied (publickey).
</code></pre>
<p>请使用：</p>
<pre><code class="language-ssh">exit
</code></pre>
<p><strong>退出ssh！</strong></p>
<h3><span id="注意">注意！</span></h3>
<p>若出现如下SSH提示，输入yes即可：</p>
<p><img src="https://s2.loli.net/2024/09/29/n71om5iAyrFUMkN.png" alt="5"></p>
<p>启动时可能会出现如下 WARN 提示：WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable WARN 提示可以忽略，并不会影响正常使用。</p>
<p>启动 Hadoop 时提示 Could not resolve hostname 如果启动 Hadoop 时遇到输出非常多“ssh: Could not resolve hostname xxx”的异常情况，如下图所示：</p>
<p><img src="https://s2.loli.net/2024/09/29/SmkjwXlIM2osNAY.png" alt="6"></p>
<p>这个并不是 ssh 的问题，可通过设置 Hadoop 环境变量来解决。首先按键盘的 ctrl + c 中断启动，然后在 ~/.bashrc 中，增加如下两行内容（设置过程与 JAVA_HOME 变量一样，其中 HADOOP_HOME 为 Hadoop 的安装目录）：</p>
<pre><code>export HADOOP_HOME=/usr/local/hadoop
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
</code></pre>
<p>保存后，务必执行 source ~/.bashrc 使变量设置生效，然后再次执行 ./sbin/start-dfs.sh 启动 Hadoop。</p>
<p>启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode” 和 “SecondaryNameNode”（如果 SecondaryNameNode 没有启动，请运行 sbin/stop-dfs.sh 关闭进程，然后再次尝 试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。</p>
<p>使用后：</p>
<p><img src="https://s2.loli.net/2024/09/29/gJ8zF6boCySwmda.png" alt="7"></p>
<h3><span id="hadoop无法正常启动的解决方法">Hadoop无法正常启动的解决方法</span></h3>
<ul>
<li>一般可以查看启动日志来排查原因，注意几点： 启动时会提示形如 “DBLab-XMU: starting namenode, logging to /usr/local/hadoop/logs/hadoop-hadoopnamenode-DBLab-XMU.out”，其中 DBLab-XMU 对应你的机器名，但其实启动日志信息是记录在 /usr/local/hadoop/logs/hadoop-hadoop-namenode-DBLab-XMU.log 中，所以应该查看这个后缀为 .log 的 文件；</li>
<li>每一次的启动日志都是追加在日志文件之后，所以得拉到最后面看，对比下记录的时间就知道了。</li>
<li>一般出错的提示在最后面，通常是写着 Fatal、Error、Warning 或者 Java Exception 的地方。</li>
<li>可以在网上搜索一下出错信息，看能否找到一些相关的解决方法</li>
</ul>
<p>此外，若是 DataNode 没有启动，可尝试如下的方法（注意这会删除 HDFS 中原有的所有数据，如果原有的 数据很重要请不要这样做）：</p>
<pre><code class="language-ssh">$ # 针对 DataNode 没法启动的解决方法
$ cd /usr/local/hadoop
$ ./sbin/stop-dfs.sh # 关闭
$ rm -r ./tmp # 删除 tmp 文件，注意这会删除 HDFS 中原有的所有数据
$ ./bin/hdfs namenode -format # 重新格式化 NameNode
$ ./sbin/start-dfs.sh # 重启
</code></pre>
<h2><span id="运行hadoop伪分布式实例">运行Hadoop伪分布式实例</span></h2>
<p>上面的单机模式，grep 例子读取的是本地数据，伪分布式读取的则是 HDFS 上的数据。要使用 HDFS，首先需要在 HDFS 中创建用户目录：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hdfs dfs -mkdir -p /user/hadoop
</code></pre>
<p>接着将 ./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制 到分布式文件系统中的 /user/hadoop/input 中。我们使用的是 hadoop 用户，并且已创建相应的用户目录 /user/hadoop ，因此在命令中就可以使用相对路径如 input，其对应的绝对路径就是 /user/hadoop/input:</p>
<pre><code>hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hdfs dfs -mkdir  -p /user/hadoop/input
hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hdfs dfs -put ./etc/hadoop/*.xml input
</code></pre>
<p>可以使用ls查看一下文件信息：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hdfs dfs -ls input
Found 9 items
-rw-r--r--   1 hadoop supergroup       9213 2022-04-14 13:37 input/capacity-scheduler.xml
-rw-r--r--   1 hadoop supergroup       1033 2022-04-14 13:37 input/core-site.xml
-rw-r--r--   1 hadoop supergroup      11392 2022-04-14 13:37 input/hadoop-policy.xml
-rw-r--r--   1 hadoop supergroup       1079 2022-04-14 13:37 input/hdfs-site.xml
-rw-r--r--   1 hadoop supergroup        620 2022-04-14 13:37 input/httpfs-site.xml
-rw-r--r--   1 hadoop supergroup       3518 2022-04-14 13:37 input/kms-acls.xml
-rw-r--r--   1 hadoop supergroup        682 2022-04-14 13:37 input/kms-site.xml
-rw-r--r--   1 hadoop supergroup        758 2022-04-14 13:37 input/mapred-site.xml
-rw-r--r--   1 hadoop supergroup        690 2022-04-14 13:37 input/yarn-site.xml
</code></pre>
<p>伪分布式运行 MapReduce 作业的方式跟单机模式相同，区别在于伪分布式读取的是HDFS中的文件（可以将单机步 骤中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。</p>
<p>注意：命令没有换行：</p>
<pre><code class="language-ssh"> hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
</code></pre>
<p><img src="https://s2.loli.net/2024/09/29/IsaTWyZhPClrBKt.png" alt="8"></p>
<p>查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hdfs dfs -cat output/*
1       dfsadmin
1       dfs.replication
1       dfs.namenode.name.dir
1       dfs.datanode.data.dir
</code></pre>
<p>Hadoop 运行程序时，输出目录不能存在，否则会提示错误 <strong>“org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/user/hadoop/output already exists”</strong></p>
<p>因此若要再次执行，需要执行如下命令删除 output 文件夹:</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$ ./bin/hdfs dfs -rm -r output
Deleted output
</code></pre>
<h3><span id="注意">注意！</span></h3>
<p>运行程序时，输出目录不能存在 运行 Hadoop 程序时，为了防止覆盖结果，程序指定的输出目录（如 output）不能存在，否则会提示错误， 因此运行前需要先删除输出目录。在实际开发应用程序时，可考虑在程序中加上如下代码，能在每次运行时 自动删除输出目录，避免繁琐的命令行操作：</p>
<pre><code class="language-java">Configuration conf = new Configuration();
Job job = new Job(conf);
/* 删除输出目录 */
Path outputPath = new Path(args[1]);
outputPath.getFileSystem(conf).delete(outputPath, true);
</code></pre>
<p>若要关闭 Hadoop，则运行：</p>
<pre><code class="language-ssh">hadoop@LAPTOP-74GAR8S9:/usr/local/hadoop$  ./sbin/stop-dfs.sh
Stopping namenodes on [localhost]
Stopping datanodes
Stopping secondary namenodes [LAPTOP-74GAR8S9]
</code></pre>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2024/10/22/Spark(2)/" title="Spark的WSL环境安装与Hadoop环境配置（贰）"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">上一页: Spark的WSL环境安装与Hadoop环境配置（贰）</span></a><a class="button is-default" href="/2024/10/22/Spark(5)/" title="Spark快速大数据分析——Spark的结构化数据API（伍）"><span class="has-text-weight-semibold">下一页: Spark快速大数据分析——Spark的结构化数据API（伍）</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container" id="vcomments" data-comment_valine_id="hUPsiqArOXp6TNWbIGsRugoz-gzGzoHsz" data-comment_valine_key="bMOEIPDsFffDM5KYhZcZFDwr"></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/NeoNexusX"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> NeoNexus 2025</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span>Puravida & FreeWill</span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script><script type="text/javascript">window.MathJax = {
  tex: {
    inlineMath: [['$', '$']],
    displayMath: [['$$', '$$']],
    processEscapes: true,
    tags: 'ams' // 如果需要支持自动编号
 },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    enableMenu: true,
  },
  startup: {
    ready: () => {
      MathJax.startup.defaultReady();
      MathJax.startup.promise.then(() => {
        // 处理公式渲染完成后的回调函数
        document.querySelectorAll('.MathJax').forEach((el) => {
          el.parentNode.classList.add('has-jax');
        });
      });
    }
  }
};</script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script src="https://unpkg.com/mermaid@10.6.1/dist/mermaid.min.js"></script><script>function initMermaid() {
  if (window.mermaid) {
    mermaid.initialize({ theme: 'forest' });
  }
}</script></body></html>